{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c44b8da-5cb6-463f-b275-0be5085026fa",
   "metadata": {},
   "source": [
    "# Omnipose with multiple channels\n",
    "Omnipose inhertis the capability of Cellpose to segment based on multi-channel images. We will use this as an opportinity to show how we can run several models at once on the same image(s), in this case comparing Omnipose to Cellpose trained on the cyto2 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc143f-0aff-4a81-a7ff-d019a84bd127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# First, import dependencies.\n",
    "import numpy as np\n",
    "import time, os, sys\n",
    "from cellpose import models, core, utils\n",
    "\n",
    "\n",
    "# This checks to see if you have set up your GPU properly.\n",
    "# CPU performance is a lot slower, but not a problem if you are only processing a few images.\n",
    "use_GPU = core.use_gpu()\n",
    "print('>>> GPU activated? %d'%use_GPU)\n",
    "\n",
    "# for plotting \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa495d2c-1bfd-49ba-9dcc-89615cf48e8f",
   "metadata": {},
   "source": [
    "### Load files\n",
    "This is one of the images from the cyto2 test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e351e50b-fa03-473b-bc07-835e8e315b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import skimage.io\n",
    "\n",
    "\n",
    "urls = ['http://www.cellpose.org/static/images/img02.png']\n",
    "files = []\n",
    "for url in urls:\n",
    "    parts = urlparse(url)\n",
    "    filename = os.path.basename(parts.path)\n",
    "    if not os.path.exists(filename):\n",
    "        sys.stderr.write('Downloading: \"{}\" to {}\\n'.format(url, filename))\n",
    "        utils.download_url_to_file(url, filename)\n",
    "    files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ef5c-8c1a-44d1-9601-48712cde8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [skimage.io.imread(f) for f in files]\n",
    "imgs = [np.stack((im[...,-1],im[...,1])) for im in imgs] # put cytosol in 1st channel, nucleus in 2nd\n",
    "nimg = len(imgs)\n",
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8337f9-5ba1-46f4-8302-a21278a274f3",
   "metadata": {},
   "source": [
    "Read in the images from the file list. It's a good idea to display the images before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd67a3b-435d-45a3-b966-cfee2f29ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import io, transforms \n",
    "\n",
    "# print some infor about the images \n",
    "for i in imgs:\n",
    "    print(i.shape)\n",
    "nimg = len(imgs)\n",
    "print(nimg)\n",
    "\n",
    "plt.figure(figsize=[2]*2) # initialize figure\n",
    "for k in range(len(imgs)):\n",
    "    # img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "    imgs[k] = transforms.normalize99(imgs[k],omni=True)\n",
    "    plt.subplot(1,len(files),k+1)\n",
    "    rgb = np.stack((imgs[k][0],imgs[k][1],np.zeros_like(imgs[k][0])),axis=-1)\n",
    "    plt.imshow(rgb) \n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635d57e-72e7-415b-aea5-73990f9450e2",
   "metadata": {},
   "source": [
    "### Initialize Models\n",
    "most recent model traied via \n",
    "python -m cellpose --train --use_gpu --dir /home/kcutler/DataDrive/cyto2/train --mask_filter _masks --n_epochs 4000 --pretrained_model None  --learning_rate 0.1 --diameter 36 --save_every 50 --save_each --omni --verbose --chan 1 --chan2 2 --RAdam --batch_size 16 --img_filter _img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626923fe-1fb0-43f8-a95e-d3716854f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = ['cyto2','cyto2_omni']\n",
    "# L = len(model_name)\n",
    "# model = [models.CellposeModel(gpu=use_GPU, model_type=model_name[i]) for i in range(L)]\n",
    "model_name = ['cyto2','cyto2_omni_bit loss']\n",
    "L = len(model_name)\n",
    "\n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_15_00_39_49.881936_epoch_301' #oops, no size model! maybe that's why it is taking cyto2 so long to train \n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_16_01_24_45.606751_epoch_151'\n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_16_01_24_45.606751_epoch_701'\n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_16_01_24_45.606751_epoch_2551'\n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_20_01_22_30.215064_epoch_251'\n",
    "modeldir = '/home/kcutler/DataDrive/cyto2/train/models/cellpose_residual_on_style_on_concatenation_off_omni_train_2022_04_22_17_55_58.018802_epoch_3999'\n",
    "\n",
    "\n",
    "model = [models.CellposeModel(gpu=use_GPU, model_type='cyto'), \n",
    "         models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir,diam_mean=36)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469856ad-65c8-4ba7-b371-e2661516c413",
   "metadata": {},
   "source": [
    "### Run segmentation \n",
    "The channels input can be very confusing. In the Cellpose documentation, it is stated that the list `[chan,chan2]` should represent the main channel to segment (`chan`) and the optional nuclear channel (`chan2`). But to train via CLI, `chan` is the \"channel to segment\" and `chan2` is the nuclear channel, and the Cellpose team states the CLI command used to train their model used `--chan 2 --chan2 1`. Because 0 is grayscale and 1,2,3 are R,G,B, this means that the given training comman actually trains with GREEN cytosol and RED nuclei. This might imply that the cyto2_omni model actually ws trained incorrectly. \n",
    "\n",
    "On top of this, the downloaded image has blue nuclei and green cytosol, whereas the cyto2 dataset shows cytosol as channel 0 and nuclei as channel 1. So in fact, I should have trained the cyto2_omni model with `--chan 1 --chan2 2'. (Have not yet done this with most recent models...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e3476-cf5f-49fe-960b-4faeac822b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# chans = [[2,3],[2,1]] # green cytoplasm and blue nucleus; cellpose documentation is confusing about this\n",
    "chans = [[2,1],[1,2]] # green cytoplasm and blue nucleus; cellpose documentation is confusing about this\n",
    "chans = [[2,1],[2,1]]\n",
    "n = range(nimg) \n",
    "\n",
    "# define parameters\n",
    "mask_threshold = [-1,-1,-2] #new model might need a bit lower \n",
    "verbose = 0 # turn on if you want to see more output \n",
    "use_gpu = use_GPU #defined above\n",
    "transparency = True # transparency in flow output\n",
    "rescale= None # give this a number if you need to upscale or downscale your images\n",
    "flow_threshold = 0 # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "resample = 0 #whether or not to run dynamics on rescaled grid or original grid \n",
    "# resampel might be broken now\n",
    "\n",
    "N = L+1 # three options: pure cellpose, mixed, omnipose, new omnipose\n",
    "omni = [0,1,1]\n",
    "ind = [0,0,1]\n",
    "masks, flows, styles = [[]]*N, [[]]*N, [[]]*N\n",
    "\n",
    "diameter = 29\n",
    "for i in range(N):\n",
    "    masks[i], flows[i], styles[i] = model[ind[i]].eval([imgs[i] for i in n],channels=chans[ind[i]],diameter=diameter,\n",
    "                                                       mask_threshold=mask_threshold[i],\n",
    "                                                       transparency=transparency,flow_threshold=flow_threshold,\n",
    "                                                       omni=omni[i], #toggle omni\n",
    "                                                       resample=resample,verbose=verbose, \n",
    "                                                       cluster=omni[i],\n",
    "                                                       interp=True, tile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd703c-6a6a-49fc-b9ff-ffb0559d2bcb",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9976c6b0-281e-4363-85bf-9e52cb26be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import plot\n",
    "import omnipose\n",
    "\n",
    "for idx,i in enumerate(n):\n",
    "    \n",
    "    for k,ki in enumerate(ind):\n",
    "        \n",
    "        print('model is:',model_name[ki],', omni is:',omni[ki])\n",
    "        maski = masks[k][idx]\n",
    "        flowi = flows[k][idx][0]\n",
    "        fig = plt.figure(figsize=(12,5))\n",
    "        # im = transforms.move_min_dim(imgs[i])\n",
    "        # print(im.shape)\n",
    "        plot.show_segmentation(fig, imgs[i], maski, flowi, channels=chans[i], omni=True, bg_color=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd475e91-1ebf-4227-a129-2beef54dcac9",
   "metadata": {},
   "source": [
    "Some comments on the above: omni preprocesses the images slightly differently (see `normalize99`) and therefore the flow is a bit different even with the same model and imput image compared to stock cyto2. The `cluster` option helps a lot to get accurate masks with Omnipose. You will notice that the omni field looks almost identical to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2824cd3-5279-4a3b-bf6c-93e87692294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = io.imread('/home/kcutler/DataDrive/cyto2_(images_cyto_oct_server)/train/000_img.tif')\n",
    "im = np.stack((imgs[0][...,1],imgs[0][...,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d541f35f-af3c-485f-919e-6d5ea02699bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs[0].shape\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16a9a19-9b5a-4bca-9a0e-49c4fd2352f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04a7e-4fdc-4363-8165-5f44ed2f2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldir = \n",
    "nclasses = 4\n",
    "model = models.CellposeModel(gpu=use_GPU, pretrained_model=modeldir, net_avg=False, diam_mean=diam_mean, nclasses=nclasses)\n",
    "#     diameters =\n",
    "\n",
    "m,f,s = model.eval([im for i in n],channels=[2,1],rescale=rescale,mask_threshold=mask_threshold,\n",
    "                                               transparency=transparency,flow_threshold=flow_threshold,omni=1,\n",
    "                                               resample=resample,verbose=verbose, cluster=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5522ff-913f-41b3-9795-4309fc51d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maski = m[0]\n",
    "flowi = f[0][0]\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "plot.show_segmentation(fig, im, maski, flowi, channels=[2,1], omni=True, bg_color=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f88c06-d8b3-486c-a5d9-facba329f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = flows[-1][0][2]\n",
    "\n",
    "plt.imshow(dist>-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5dfff2-0d7f-4c43-86bb-005689688862",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plt.hist(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543c984-f037-4839-80cb-fa1fdb35f646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
